{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "LeHtnvThC59o"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('https://raw.githubusercontent.com/gscdit/Breast-Cancer-Detection/refs/heads/master/data.csv')\n",
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "id": "8Yy4uOooDV57",
        "outputId": "6ddd3eae-854e-4368-afc0-6790e1322f88"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         id diagnosis  ...  fractal_dimension_worst  Unnamed: 32\n",
              "0    842302         M  ...                  0.11890          NaN\n",
              "1    842517         M  ...                  0.08902          NaN\n",
              "2  84300903         M  ...                  0.08758          NaN\n",
              "3  84348301         M  ...                  0.17300          NaN\n",
              "4  84358402         M  ...                  0.07678          NaN\n",
              "\n",
              "[5 rows x 33 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cb932676-7e56-4708-beb8-3c61bb516b73\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>diagnosis</th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>symmetry_mean</th>\n",
              "      <th>fractal_dimension_mean</th>\n",
              "      <th>radius_se</th>\n",
              "      <th>texture_se</th>\n",
              "      <th>perimeter_se</th>\n",
              "      <th>area_se</th>\n",
              "      <th>smoothness_se</th>\n",
              "      <th>compactness_se</th>\n",
              "      <th>concavity_se</th>\n",
              "      <th>concave points_se</th>\n",
              "      <th>symmetry_se</th>\n",
              "      <th>fractal_dimension_se</th>\n",
              "      <th>radius_worst</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "      <th>Unnamed: 32</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>842302</td>\n",
              "      <td>M</td>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.3001</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>1.0950</td>\n",
              "      <td>0.9053</td>\n",
              "      <td>8.589</td>\n",
              "      <td>153.40</td>\n",
              "      <td>0.006399</td>\n",
              "      <td>0.04904</td>\n",
              "      <td>0.05373</td>\n",
              "      <td>0.01587</td>\n",
              "      <td>0.03003</td>\n",
              "      <td>0.006193</td>\n",
              "      <td>25.38</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.1622</td>\n",
              "      <td>0.6656</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>842517</td>\n",
              "      <td>M</td>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.0869</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>0.5435</td>\n",
              "      <td>0.7339</td>\n",
              "      <td>3.398</td>\n",
              "      <td>74.08</td>\n",
              "      <td>0.005225</td>\n",
              "      <td>0.01308</td>\n",
              "      <td>0.01860</td>\n",
              "      <td>0.01340</td>\n",
              "      <td>0.01389</td>\n",
              "      <td>0.003532</td>\n",
              "      <td>24.99</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.1238</td>\n",
              "      <td>0.1866</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>84300903</td>\n",
              "      <td>M</td>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.1974</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>0.7456</td>\n",
              "      <td>0.7869</td>\n",
              "      <td>4.585</td>\n",
              "      <td>94.03</td>\n",
              "      <td>0.006150</td>\n",
              "      <td>0.04006</td>\n",
              "      <td>0.03832</td>\n",
              "      <td>0.02058</td>\n",
              "      <td>0.02250</td>\n",
              "      <td>0.004571</td>\n",
              "      <td>23.57</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.1444</td>\n",
              "      <td>0.4245</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>84348301</td>\n",
              "      <td>M</td>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.2414</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>0.4956</td>\n",
              "      <td>1.1560</td>\n",
              "      <td>3.445</td>\n",
              "      <td>27.23</td>\n",
              "      <td>0.009110</td>\n",
              "      <td>0.07458</td>\n",
              "      <td>0.05661</td>\n",
              "      <td>0.01867</td>\n",
              "      <td>0.05963</td>\n",
              "      <td>0.009208</td>\n",
              "      <td>14.91</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.2098</td>\n",
              "      <td>0.8663</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>84358402</td>\n",
              "      <td>M</td>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.1980</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>0.7572</td>\n",
              "      <td>0.7813</td>\n",
              "      <td>5.438</td>\n",
              "      <td>94.44</td>\n",
              "      <td>0.011490</td>\n",
              "      <td>0.02461</td>\n",
              "      <td>0.05688</td>\n",
              "      <td>0.01885</td>\n",
              "      <td>0.01756</td>\n",
              "      <td>0.005115</td>\n",
              "      <td>22.54</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.1374</td>\n",
              "      <td>0.2050</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cb932676-7e56-4708-beb8-3c61bb516b73')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-cb932676-7e56-4708-beb8-3c61bb516b73 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-cb932676-7e56-4708-beb8-3c61bb516b73');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-1aa3ab8d-d1fc-46b5-ab0b-09af7c38bece\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1aa3ab8d-d1fc-46b5-ab0b-09af7c38bece')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-1aa3ab8d-d1fc-46b5-ab0b-09af7c38bece button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data"
            }
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uAC1V92_DV2c",
        "outputId": "86997a6a-9c89-4c35-a6fc-bee5efff6d2e"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 569 entries, 0 to 568\n",
            "Data columns (total 33 columns):\n",
            " #   Column                   Non-Null Count  Dtype  \n",
            "---  ------                   --------------  -----  \n",
            " 0   id                       569 non-null    int64  \n",
            " 1   diagnosis                569 non-null    object \n",
            " 2   radius_mean              569 non-null    float64\n",
            " 3   texture_mean             569 non-null    float64\n",
            " 4   perimeter_mean           569 non-null    float64\n",
            " 5   area_mean                569 non-null    float64\n",
            " 6   smoothness_mean          569 non-null    float64\n",
            " 7   compactness_mean         569 non-null    float64\n",
            " 8   concavity_mean           569 non-null    float64\n",
            " 9   concave points_mean      569 non-null    float64\n",
            " 10  symmetry_mean            569 non-null    float64\n",
            " 11  fractal_dimension_mean   569 non-null    float64\n",
            " 12  radius_se                569 non-null    float64\n",
            " 13  texture_se               569 non-null    float64\n",
            " 14  perimeter_se             569 non-null    float64\n",
            " 15  area_se                  569 non-null    float64\n",
            " 16  smoothness_se            569 non-null    float64\n",
            " 17  compactness_se           569 non-null    float64\n",
            " 18  concavity_se             569 non-null    float64\n",
            " 19  concave points_se        569 non-null    float64\n",
            " 20  symmetry_se              569 non-null    float64\n",
            " 21  fractal_dimension_se     569 non-null    float64\n",
            " 22  radius_worst             569 non-null    float64\n",
            " 23  texture_worst            569 non-null    float64\n",
            " 24  perimeter_worst          569 non-null    float64\n",
            " 25  area_worst               569 non-null    float64\n",
            " 26  smoothness_worst         569 non-null    float64\n",
            " 27  compactness_worst        569 non-null    float64\n",
            " 28  concavity_worst          569 non-null    float64\n",
            " 29  concave points_worst     569 non-null    float64\n",
            " 30  symmetry_worst           569 non-null    float64\n",
            " 31  fractal_dimension_worst  569 non-null    float64\n",
            " 32  Unnamed: 32              0 non-null      float64\n",
            "dtypes: float64(31), int64(1), object(1)\n",
            "memory usage: 146.8+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "id": "02L_Bgi_DVzA",
        "outputId": "b22bfa55-76a1-4290-c893-4e595bbbf453"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 id  radius_mean  ...  fractal_dimension_worst  Unnamed: 32\n",
              "count  5.690000e+02   569.000000  ...               569.000000          0.0\n",
              "mean   3.037183e+07    14.127292  ...                 0.083946          NaN\n",
              "std    1.250206e+08     3.524049  ...                 0.018061          NaN\n",
              "min    8.670000e+03     6.981000  ...                 0.055040          NaN\n",
              "25%    8.692180e+05    11.700000  ...                 0.071460          NaN\n",
              "50%    9.060240e+05    13.370000  ...                 0.080040          NaN\n",
              "75%    8.813129e+06    15.780000  ...                 0.092080          NaN\n",
              "max    9.113205e+08    28.110000  ...                 0.207500          NaN\n",
              "\n",
              "[8 rows x 32 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-195a2e29-8dd5-4872-a305-960373eddc2d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>symmetry_mean</th>\n",
              "      <th>fractal_dimension_mean</th>\n",
              "      <th>radius_se</th>\n",
              "      <th>texture_se</th>\n",
              "      <th>perimeter_se</th>\n",
              "      <th>area_se</th>\n",
              "      <th>smoothness_se</th>\n",
              "      <th>compactness_se</th>\n",
              "      <th>concavity_se</th>\n",
              "      <th>concave points_se</th>\n",
              "      <th>symmetry_se</th>\n",
              "      <th>fractal_dimension_se</th>\n",
              "      <th>radius_worst</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "      <th>Unnamed: 32</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>5.690000e+02</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>3.037183e+07</td>\n",
              "      <td>14.127292</td>\n",
              "      <td>19.289649</td>\n",
              "      <td>91.969033</td>\n",
              "      <td>654.889104</td>\n",
              "      <td>0.096360</td>\n",
              "      <td>0.104341</td>\n",
              "      <td>0.088799</td>\n",
              "      <td>0.048919</td>\n",
              "      <td>0.181162</td>\n",
              "      <td>0.062798</td>\n",
              "      <td>0.405172</td>\n",
              "      <td>1.216853</td>\n",
              "      <td>2.866059</td>\n",
              "      <td>40.337079</td>\n",
              "      <td>0.007041</td>\n",
              "      <td>0.025478</td>\n",
              "      <td>0.031894</td>\n",
              "      <td>0.011796</td>\n",
              "      <td>0.020542</td>\n",
              "      <td>0.003795</td>\n",
              "      <td>16.269190</td>\n",
              "      <td>25.677223</td>\n",
              "      <td>107.261213</td>\n",
              "      <td>880.583128</td>\n",
              "      <td>0.132369</td>\n",
              "      <td>0.254265</td>\n",
              "      <td>0.272188</td>\n",
              "      <td>0.114606</td>\n",
              "      <td>0.290076</td>\n",
              "      <td>0.083946</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.250206e+08</td>\n",
              "      <td>3.524049</td>\n",
              "      <td>4.301036</td>\n",
              "      <td>24.298981</td>\n",
              "      <td>351.914129</td>\n",
              "      <td>0.014064</td>\n",
              "      <td>0.052813</td>\n",
              "      <td>0.079720</td>\n",
              "      <td>0.038803</td>\n",
              "      <td>0.027414</td>\n",
              "      <td>0.007060</td>\n",
              "      <td>0.277313</td>\n",
              "      <td>0.551648</td>\n",
              "      <td>2.021855</td>\n",
              "      <td>45.491006</td>\n",
              "      <td>0.003003</td>\n",
              "      <td>0.017908</td>\n",
              "      <td>0.030186</td>\n",
              "      <td>0.006170</td>\n",
              "      <td>0.008266</td>\n",
              "      <td>0.002646</td>\n",
              "      <td>4.833242</td>\n",
              "      <td>6.146258</td>\n",
              "      <td>33.602542</td>\n",
              "      <td>569.356993</td>\n",
              "      <td>0.022832</td>\n",
              "      <td>0.157336</td>\n",
              "      <td>0.208624</td>\n",
              "      <td>0.065732</td>\n",
              "      <td>0.061867</td>\n",
              "      <td>0.018061</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>8.670000e+03</td>\n",
              "      <td>6.981000</td>\n",
              "      <td>9.710000</td>\n",
              "      <td>43.790000</td>\n",
              "      <td>143.500000</td>\n",
              "      <td>0.052630</td>\n",
              "      <td>0.019380</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.106000</td>\n",
              "      <td>0.049960</td>\n",
              "      <td>0.111500</td>\n",
              "      <td>0.360200</td>\n",
              "      <td>0.757000</td>\n",
              "      <td>6.802000</td>\n",
              "      <td>0.001713</td>\n",
              "      <td>0.002252</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.007882</td>\n",
              "      <td>0.000895</td>\n",
              "      <td>7.930000</td>\n",
              "      <td>12.020000</td>\n",
              "      <td>50.410000</td>\n",
              "      <td>185.200000</td>\n",
              "      <td>0.071170</td>\n",
              "      <td>0.027290</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.156500</td>\n",
              "      <td>0.055040</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>8.692180e+05</td>\n",
              "      <td>11.700000</td>\n",
              "      <td>16.170000</td>\n",
              "      <td>75.170000</td>\n",
              "      <td>420.300000</td>\n",
              "      <td>0.086370</td>\n",
              "      <td>0.064920</td>\n",
              "      <td>0.029560</td>\n",
              "      <td>0.020310</td>\n",
              "      <td>0.161900</td>\n",
              "      <td>0.057700</td>\n",
              "      <td>0.232400</td>\n",
              "      <td>0.833900</td>\n",
              "      <td>1.606000</td>\n",
              "      <td>17.850000</td>\n",
              "      <td>0.005169</td>\n",
              "      <td>0.013080</td>\n",
              "      <td>0.015090</td>\n",
              "      <td>0.007638</td>\n",
              "      <td>0.015160</td>\n",
              "      <td>0.002248</td>\n",
              "      <td>13.010000</td>\n",
              "      <td>21.080000</td>\n",
              "      <td>84.110000</td>\n",
              "      <td>515.300000</td>\n",
              "      <td>0.116600</td>\n",
              "      <td>0.147200</td>\n",
              "      <td>0.114500</td>\n",
              "      <td>0.064930</td>\n",
              "      <td>0.250400</td>\n",
              "      <td>0.071460</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>9.060240e+05</td>\n",
              "      <td>13.370000</td>\n",
              "      <td>18.840000</td>\n",
              "      <td>86.240000</td>\n",
              "      <td>551.100000</td>\n",
              "      <td>0.095870</td>\n",
              "      <td>0.092630</td>\n",
              "      <td>0.061540</td>\n",
              "      <td>0.033500</td>\n",
              "      <td>0.179200</td>\n",
              "      <td>0.061540</td>\n",
              "      <td>0.324200</td>\n",
              "      <td>1.108000</td>\n",
              "      <td>2.287000</td>\n",
              "      <td>24.530000</td>\n",
              "      <td>0.006380</td>\n",
              "      <td>0.020450</td>\n",
              "      <td>0.025890</td>\n",
              "      <td>0.010930</td>\n",
              "      <td>0.018730</td>\n",
              "      <td>0.003187</td>\n",
              "      <td>14.970000</td>\n",
              "      <td>25.410000</td>\n",
              "      <td>97.660000</td>\n",
              "      <td>686.500000</td>\n",
              "      <td>0.131300</td>\n",
              "      <td>0.211900</td>\n",
              "      <td>0.226700</td>\n",
              "      <td>0.099930</td>\n",
              "      <td>0.282200</td>\n",
              "      <td>0.080040</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>8.813129e+06</td>\n",
              "      <td>15.780000</td>\n",
              "      <td>21.800000</td>\n",
              "      <td>104.100000</td>\n",
              "      <td>782.700000</td>\n",
              "      <td>0.105300</td>\n",
              "      <td>0.130400</td>\n",
              "      <td>0.130700</td>\n",
              "      <td>0.074000</td>\n",
              "      <td>0.195700</td>\n",
              "      <td>0.066120</td>\n",
              "      <td>0.478900</td>\n",
              "      <td>1.474000</td>\n",
              "      <td>3.357000</td>\n",
              "      <td>45.190000</td>\n",
              "      <td>0.008146</td>\n",
              "      <td>0.032450</td>\n",
              "      <td>0.042050</td>\n",
              "      <td>0.014710</td>\n",
              "      <td>0.023480</td>\n",
              "      <td>0.004558</td>\n",
              "      <td>18.790000</td>\n",
              "      <td>29.720000</td>\n",
              "      <td>125.400000</td>\n",
              "      <td>1084.000000</td>\n",
              "      <td>0.146000</td>\n",
              "      <td>0.339100</td>\n",
              "      <td>0.382900</td>\n",
              "      <td>0.161400</td>\n",
              "      <td>0.317900</td>\n",
              "      <td>0.092080</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>9.113205e+08</td>\n",
              "      <td>28.110000</td>\n",
              "      <td>39.280000</td>\n",
              "      <td>188.500000</td>\n",
              "      <td>2501.000000</td>\n",
              "      <td>0.163400</td>\n",
              "      <td>0.345400</td>\n",
              "      <td>0.426800</td>\n",
              "      <td>0.201200</td>\n",
              "      <td>0.304000</td>\n",
              "      <td>0.097440</td>\n",
              "      <td>2.873000</td>\n",
              "      <td>4.885000</td>\n",
              "      <td>21.980000</td>\n",
              "      <td>542.200000</td>\n",
              "      <td>0.031130</td>\n",
              "      <td>0.135400</td>\n",
              "      <td>0.396000</td>\n",
              "      <td>0.052790</td>\n",
              "      <td>0.078950</td>\n",
              "      <td>0.029840</td>\n",
              "      <td>36.040000</td>\n",
              "      <td>49.540000</td>\n",
              "      <td>251.200000</td>\n",
              "      <td>4254.000000</td>\n",
              "      <td>0.222600</td>\n",
              "      <td>1.058000</td>\n",
              "      <td>1.252000</td>\n",
              "      <td>0.291000</td>\n",
              "      <td>0.663800</td>\n",
              "      <td>0.207500</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-195a2e29-8dd5-4872-a305-960373eddc2d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-195a2e29-8dd5-4872-a305-960373eddc2d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-195a2e29-8dd5-4872-a305-960373eddc2d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-dd37eba0-a7ee-4595-a64e-bc3dbdb48538\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-dd37eba0-a7ee-4595-a64e-bc3dbdb48538')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-dd37eba0-a7ee-4595-a64e-bc3dbdb48538 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.drop(['id', 'Unnamed: 32'], axis=1, inplace=True)\n",
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "id": "el3UWGQ9DVv4",
        "outputId": "0ed3ebde-cd59-44f1-cb9a-a32a6683cd6c"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  diagnosis  radius_mean  ...  symmetry_worst  fractal_dimension_worst\n",
              "0         M        17.99  ...          0.4601                  0.11890\n",
              "1         M        20.57  ...          0.2750                  0.08902\n",
              "2         M        19.69  ...          0.3613                  0.08758\n",
              "3         M        11.42  ...          0.6638                  0.17300\n",
              "4         M        20.29  ...          0.2364                  0.07678\n",
              "\n",
              "[5 rows x 31 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0b3f10c3-be66-4307-b5ae-2fcb3c7c47ae\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>diagnosis</th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>symmetry_mean</th>\n",
              "      <th>fractal_dimension_mean</th>\n",
              "      <th>radius_se</th>\n",
              "      <th>texture_se</th>\n",
              "      <th>perimeter_se</th>\n",
              "      <th>area_se</th>\n",
              "      <th>smoothness_se</th>\n",
              "      <th>compactness_se</th>\n",
              "      <th>concavity_se</th>\n",
              "      <th>concave points_se</th>\n",
              "      <th>symmetry_se</th>\n",
              "      <th>fractal_dimension_se</th>\n",
              "      <th>radius_worst</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>M</td>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.3001</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>1.0950</td>\n",
              "      <td>0.9053</td>\n",
              "      <td>8.589</td>\n",
              "      <td>153.40</td>\n",
              "      <td>0.006399</td>\n",
              "      <td>0.04904</td>\n",
              "      <td>0.05373</td>\n",
              "      <td>0.01587</td>\n",
              "      <td>0.03003</td>\n",
              "      <td>0.006193</td>\n",
              "      <td>25.38</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.1622</td>\n",
              "      <td>0.6656</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>M</td>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.0869</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>0.5435</td>\n",
              "      <td>0.7339</td>\n",
              "      <td>3.398</td>\n",
              "      <td>74.08</td>\n",
              "      <td>0.005225</td>\n",
              "      <td>0.01308</td>\n",
              "      <td>0.01860</td>\n",
              "      <td>0.01340</td>\n",
              "      <td>0.01389</td>\n",
              "      <td>0.003532</td>\n",
              "      <td>24.99</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.1238</td>\n",
              "      <td>0.1866</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>M</td>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.1974</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>0.7456</td>\n",
              "      <td>0.7869</td>\n",
              "      <td>4.585</td>\n",
              "      <td>94.03</td>\n",
              "      <td>0.006150</td>\n",
              "      <td>0.04006</td>\n",
              "      <td>0.03832</td>\n",
              "      <td>0.02058</td>\n",
              "      <td>0.02250</td>\n",
              "      <td>0.004571</td>\n",
              "      <td>23.57</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.1444</td>\n",
              "      <td>0.4245</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>M</td>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.2414</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>0.4956</td>\n",
              "      <td>1.1560</td>\n",
              "      <td>3.445</td>\n",
              "      <td>27.23</td>\n",
              "      <td>0.009110</td>\n",
              "      <td>0.07458</td>\n",
              "      <td>0.05661</td>\n",
              "      <td>0.01867</td>\n",
              "      <td>0.05963</td>\n",
              "      <td>0.009208</td>\n",
              "      <td>14.91</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.2098</td>\n",
              "      <td>0.8663</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>M</td>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.1980</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>0.7572</td>\n",
              "      <td>0.7813</td>\n",
              "      <td>5.438</td>\n",
              "      <td>94.44</td>\n",
              "      <td>0.011490</td>\n",
              "      <td>0.02461</td>\n",
              "      <td>0.05688</td>\n",
              "      <td>0.01885</td>\n",
              "      <td>0.01756</td>\n",
              "      <td>0.005115</td>\n",
              "      <td>22.54</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.1374</td>\n",
              "      <td>0.2050</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0b3f10c3-be66-4307-b5ae-2fcb3c7c47ae')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0b3f10c3-be66-4307-b5ae-2fcb3c7c47ae button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0b3f10c3-be66-4307-b5ae-2fcb3c7c47ae');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-ce613b52-44db-4742-bda6-e6ab850eb781\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ce613b52-44db-4742-bda6-e6ab850eb781')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-ce613b52-44db-4742-bda6-e6ab850eb781 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data"
            }
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(data.iloc[:, 1:], data.iloc[:, 0], test_size=0.2)\n",
        "X_train.shape, X_test.shape, Y_train.shape, Y_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xht9Ex7ADVs6",
        "outputId": "0917b45a-752d-40e8-dea4-d9680e62a689"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((455, 30), (114, 30), (455,), (114,))"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "gaCcKrV-DVqR"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "le = LabelEncoder()\n",
        "Y_train = le.fit_transform(Y_train)\n",
        "Y_test = le.transform(Y_test)"
      ],
      "metadata": {
        "id": "siWvbcghDVns"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_tensor = torch.tensor(X_train)\n",
        "X_test_tensor = torch.tensor(X_test)\n",
        "Y_train_tensor = torch.tensor(Y_train)\n",
        "Y_test_tensor = torch.tensor(Y_test)"
      ],
      "metadata": {
        "id": "Hak48_HDDVjk"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_tensor.shape, X_test_tensor.shape, Y_train_tensor.shape, Y_test_tensor.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EEnaYRYtDVgt",
        "outputId": "4c4d99ae-8e37-4ffa-fc2f-7c6cc767e732"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([455, 30]),\n",
              " torch.Size([114, 30]),\n",
              " torch.Size([455]),\n",
              " torch.Size([114]))"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MySimpleNN:\n",
        "  def __init__(self, X):\n",
        "    self.weights = torch.rand(X.shape[1], 1, dtype=torch.float64, requires_grad=True)\n",
        "    self.bias = torch.zeros(1, dtype=torch.float64, requires_grad=True)\n",
        "\n",
        "  def forward(self, X):\n",
        "    z = torch.matmul(X, self.weights) + self.bias\n",
        "    y_pred = torch.sigmoid(z)\n",
        "    return y_pred\n",
        "\n",
        "  def loss(self, y_pred, Y):\n",
        "    epsilon = 1e-7\n",
        "    y_pred = torch.clamp(y_pred, epsilon, 1 - epsilon)\n",
        "    loss = Y * torch.log(y_pred) + (1 - Y) * torch.log(1 - y_pred)\n",
        "    return -torch.mean(loss)\n",
        ""
      ],
      "metadata": {
        "id": "pjcXSCYTDVeB"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 0.01\n",
        "epochs = 1000"
      ],
      "metadata": {
        "id": "MM-dT6B9DVbO"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = MySimpleNN(X_train_tensor)\n",
        "\n",
        "for i in range(epochs):\n",
        "  # forward pass\n",
        "  y_pred = model.forward(X_train_tensor)\n",
        "\n",
        "  # loss calculation\n",
        "  loss = model.loss(y_pred, Y_train_tensor)\n",
        "  print(f'Epoch: {i + 1} | Loss: {loss.item()}', end='--->')\n",
        "  if (i + 1) % 100 == 0:\n",
        "    print()\n",
        "\n",
        "  # backward pass\n",
        "  loss.backward()\n",
        "\n",
        "  # weight update\n",
        "  with torch.no_grad():\n",
        "    model.weights -= lr * model.weights.grad\n",
        "    model.bias -= lr * model.bias.grad\n",
        "\n",
        "  # zero the gradients\n",
        "  model.weights.grad.zero_()\n",
        "  model.bias.grad.zero_()\n",
        "\n",
        "model.weights, model.bias"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "28ykz0ETDVYf",
        "outputId": "9f00b909-49c3-45d4-e438-e4543f2b8c09"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 | Loss: 3.3473729651325375--->Epoch: 2 | Loss: 3.3342836639123914--->Epoch: 3 | Loss: 3.320944215780998--->Epoch: 4 | Loss: 3.3074134234401744--->Epoch: 5 | Loss: 3.293894171050222--->Epoch: 6 | Loss: 3.28038661075493--->Epoch: 7 | Loss: 3.26689089717201--->Epoch: 8 | Loss: 3.2533091549372806--->Epoch: 9 | Loss: 3.2396129380749716--->Epoch: 10 | Loss: 3.2255995380177342--->Epoch: 11 | Loss: 3.211305999014356--->Epoch: 12 | Loss: 3.1966563978451616--->Epoch: 13 | Loss: 3.1820209893427274--->Epoch: 14 | Loss: 3.1672772218219305--->Epoch: 15 | Loss: 3.1524122521418563--->Epoch: 16 | Loss: 3.13756240559396--->Epoch: 17 | Loss: 3.1227279005443886--->Epoch: 18 | Loss: 3.1079089592182236--->Epoch: 19 | Loss: 3.0931058077612765--->Epoch: 20 | Loss: 3.078318676331641--->Epoch: 21 | Loss: 3.063547799176702--->Epoch: 22 | Loss: 3.0487934147143294--->Epoch: 23 | Loss: 3.034055765618912--->Epoch: 24 | Loss: 3.019335098913774--->Epoch: 25 | Loss: 3.004551741430925--->Epoch: 26 | Loss: 2.989611164334247--->Epoch: 27 | Loss: 2.9746884802270537--->Epoch: 28 | Loss: 2.959783959601312--->Epoch: 29 | Loss: 2.944897877929857--->Epoch: 30 | Loss: 2.9300305157753535--->Epoch: 31 | Loss: 2.915168941945627--->Epoch: 32 | Loss: 2.900044895833843--->Epoch: 33 | Loss: 2.88494091731707--->Epoch: 34 | Loss: 2.8698573190124304--->Epoch: 35 | Loss: 2.8547333529121963--->Epoch: 36 | Loss: 2.8393303958282896--->Epoch: 37 | Loss: 2.823530525968713--->Epoch: 38 | Loss: 2.80760065786324--->Epoch: 39 | Loss: 2.7916943705849087--->Epoch: 40 | Loss: 2.77578931446743--->Epoch: 41 | Loss: 2.75960183214542--->Epoch: 42 | Loss: 2.7433085106785784--->Epoch: 43 | Loss: 2.7268300802955228--->Epoch: 44 | Loss: 2.710378493475721--->Epoch: 45 | Loss: 2.6939542086259616--->Epoch: 46 | Loss: 2.677547238677794--->Epoch: 47 | Loss: 2.660892029643311--->Epoch: 48 | Loss: 2.6442658497856244--->Epoch: 49 | Loss: 2.6276692064960803--->Epoch: 50 | Loss: 2.6109521456458986--->Epoch: 51 | Loss: 2.5940729277706946--->Epoch: 52 | Loss: 2.5772254967148376--->Epoch: 53 | Loss: 2.560410421346936--->Epoch: 54 | Loss: 2.5436282823945335--->Epoch: 55 | Loss: 2.5268796726761025--->Epoch: 56 | Loss: 2.5101281057758786--->Epoch: 57 | Loss: 2.493146505321853--->Epoch: 58 | Loss: 2.4761116767551345--->Epoch: 59 | Loss: 2.4587371602306067--->Epoch: 60 | Loss: 2.4410625324424906--->Epoch: 61 | Loss: 2.4234278150375315--->Epoch: 62 | Loss: 2.405672297567557--->Epoch: 63 | Loss: 2.3877784320040405--->Epoch: 64 | Loss: 2.3699274104362957--->Epoch: 65 | Loss: 2.3521200637589033--->Epoch: 66 | Loss: 2.3343572408548354--->Epoch: 67 | Loss: 2.3166398089266353--->Epoch: 68 | Loss: 2.298968653823732--->Epoch: 69 | Loss: 2.281344680399622--->Epoch: 70 | Loss: 2.2637688128432756--->Epoch: 71 | Loss: 2.24624199501168--->Epoch: 72 | Loss: 2.228765190779541--->Epoch: 73 | Loss: 2.211339384368332--->Epoch: 74 | Loss: 2.193965580691218--->Epoch: 75 | Loss: 2.1766448056780705--->Epoch: 76 | Loss: 2.1593781066112747--->Epoch: 77 | Loss: 2.142166552451887--->Epoch: 78 | Loss: 2.12501123415973--->Epoch: 79 | Loss: 2.107913265009683--->Epoch: 80 | Loss: 2.0908737809021325--->Epoch: 81 | Loss: 2.0738939406583774--->Epoch: 82 | Loss: 2.0569749263124253--->Epoch: 83 | Loss: 2.040117943387552--->Epoch: 84 | Loss: 2.023130866533136--->Epoch: 85 | Loss: 2.0058426346377525--->Epoch: 86 | Loss: 1.9883001916927043--->Epoch: 87 | Loss: 1.9708279438948875--->Epoch: 88 | Loss: 1.9534273248944571--->Epoch: 89 | Loss: 1.9360997964653002--->Epoch: 90 | Loss: 1.91884684868988--->Epoch: 91 | Loss: 1.9016700001121785--->Epoch: 92 | Loss: 1.884570797840176--->Epoch: 93 | Loss: 1.8675442488384644--->Epoch: 94 | Loss: 1.8501085016469743--->Epoch: 95 | Loss: 1.8327571754236875--->Epoch: 96 | Loss: 1.8154920072958718--->Epoch: 97 | Loss: 1.7983147650656455--->Epoch: 98 | Loss: 1.7812272469914383--->Epoch: 99 | Loss: 1.7642312815004058--->Epoch: 100 | Loss: 1.747328726799317--->\n",
            "Epoch: 101 | Loss: 1.7305214704099043--->Epoch: 102 | Loss: 1.7138114286013892--->Epoch: 103 | Loss: 1.6972005457289618--->Epoch: 104 | Loss: 1.680690793459274--->Epoch: 105 | Loss: 1.6642841698942261--->Epoch: 106 | Loss: 1.6479826985819164--->Epoch: 107 | Loss: 1.631788427409606--->Epoch: 108 | Loss: 1.6157034273805042--->Epoch: 109 | Loss: 1.5997297912731798--->Epoch: 110 | Loss: 1.5838696321791685--->Epoch: 111 | Loss: 1.5681250819221164--->Epoch: 112 | Loss: 1.5524982893591746--->Epoch: 113 | Loss: 1.5369914185667377--->Epoch: 114 | Loss: 1.5216066469118763--->Epoch: 115 | Loss: 1.5063461630174353--->Epoch: 116 | Loss: 1.4912121646216616--->Epoch: 117 | Loss: 1.476206856341409--->Epoch: 118 | Loss: 1.4613324473437703--->Epoch: 119 | Loss: 1.4465911489338512--->Epoch: 120 | Loss: 1.4319851720661514--->Epoch: 121 | Loss: 1.4175167247870355--->Epoch: 122 | Loss: 1.4031880096161422--->Epoch: 123 | Loss: 1.3890012208737839--->Epoch: 124 | Loss: 1.3749585419613402--->Epoch: 125 | Loss: 1.3610621426002465--->Epoch: 126 | Loss: 1.3473141760348886--->Epoch: 127 | Loss: 1.3337167762026538--->Epoch: 128 | Loss: 1.3202720548735294--->Epoch: 129 | Loss: 1.3069820987597636--->Epoch: 130 | Loss: 1.2938489665945954--->Epoch: 131 | Loss: 1.2808746861770128--->Epoch: 132 | Loss: 1.2680612513782386--->Epoch: 133 | Loss: 1.2554106191035803--->Epoch: 134 | Loss: 1.2429247062021294--->Epoch: 135 | Loss: 1.230605386315279--->Epoch: 136 | Loss: 1.2184544866542701--->Epoch: 137 | Loss: 1.2064737846961588--->Epoch: 138 | Loss: 1.1946650047873697--->Epoch: 139 | Loss: 1.1830298146442035--->Epoch: 140 | Loss: 1.1715698217401895--->Epoch: 141 | Loss: 1.160286569571331--->Epoch: 142 | Loss: 1.1491815337918163--->Epoch: 143 | Loss: 1.1382561182148632--->Epoch: 144 | Loss: 1.1275116506758924--->Epoch: 145 | Loss: 1.1169493787582303--->Epoch: 146 | Loss: 1.1065704653849893--->Epoch: 147 | Loss: 1.0963759842845644--->Epoch: 148 | Loss: 1.086366915341367--->Epoch: 149 | Loss: 1.0765441398478142--->Epoch: 150 | Loss: 1.0669084356782526--->Epoch: 151 | Loss: 1.0574604724102334--->Epoch: 152 | Loss: 1.0482008064233717--->Epoch: 153 | Loss: 1.0391298760107677--->Epoch: 154 | Loss: 1.0302479965425861--->Epoch: 155 | Loss: 1.0215553557257415--->Epoch: 156 | Loss: 1.013052009007642--->Epoch: 157 | Loss: 1.0047378751754914--->Epoch: 158 | Loss: 0.9966127322055959--->Epoch: 159 | Loss: 0.9886762134194172--->Epoch: 160 | Loss: 0.980927804004572--->Epoch: 161 | Loss: 0.9733668379595747--->Epoch: 162 | Loss: 0.9659924955206978--->Epoch: 163 | Loss: 0.9588038011278377--->Epoch: 164 | Loss: 0.951799621983638--->Epoch: 165 | Loss: 0.9449786672562942--->Epoch: 166 | Loss: 0.9383394879714403--->Epoch: 167 | Loss: 0.9318804776322712--->Epoch: 168 | Loss: 0.9255998735996693--->Epoch: 169 | Loss: 0.919495759255641--->Epoch: 170 | Loss: 0.9135660669639413--->Epoch: 171 | Loss: 0.9078085818315745--->Epoch: 172 | Loss: 0.9022209462640445--->Epoch: 173 | Loss: 0.8968006652960983--->Epoch: 174 | Loss: 0.8915451126684661--->Epoch: 175 | Loss: 0.8864515376100723--->Epoch: 176 | Loss: 0.8815170722746506--->Epoch: 177 | Loss: 0.8767387397709574--->Epoch: 178 | Loss: 0.8721134627170842--->Epoch: 179 | Loss: 0.8676380722420152--->Epoch: 180 | Loss: 0.8633093173517276--->Epoch: 181 | Loss: 0.859123874572984--->Epoch: 182 | Loss: 0.8550783577855907--->Epoch: 183 | Loss: 0.851169328153351--->Epoch: 184 | Loss: 0.8473933040651923--->Epoch: 185 | Loss: 0.8437467710008908--->Epoch: 186 | Loss: 0.8402261912403363--->Epoch: 187 | Loss: 0.8368280133411479--->Epoch: 188 | Loss: 0.8335486813164605--->Epoch: 189 | Loss: 0.8303846434525727--->Epoch: 190 | Loss: 0.8273323607146315--->Epoch: 191 | Loss: 0.824388314697338--->Epoch: 192 | Loss: 0.8215490150865385--->Epoch: 193 | Loss: 0.818811006606287--->Epoch: 194 | Loss: 0.8161708754343108--->Epoch: 195 | Loss: 0.8136252550766153--->Epoch: 196 | Loss: 0.8111708316990883--->Epoch: 197 | Loss: 0.8088043489203167--->Epoch: 198 | Loss: 0.8065226120753503--->Epoch: 199 | Loss: 0.8043224919648241--->Epoch: 200 | Loss: 0.8022009281076761--->\n",
            "Epoch: 201 | Loss: 0.8001549315187196--->Epoch: 202 | Loss: 0.7981815870346092--->Epoch: 203 | Loss: 0.7962780552133185--->Epoch: 204 | Loss: 0.7944415738332454--->Epoch: 205 | Loss: 0.7926694590185244--->Epoch: 206 | Loss: 0.7909591060171678--->Epoch: 207 | Loss: 0.7893079896583357--->Epoch: 208 | Loss: 0.7877136645144465--->Epoch: 209 | Loss: 0.786173764793033--->Epoch: 210 | Loss: 0.7846860039822998--->Epoch: 211 | Loss: 0.7832481742732817--->Epoch: 212 | Loss: 0.7818581457803896--->Epoch: 213 | Loss: 0.7805138655809971--->Epoch: 214 | Loss: 0.7792133565935663--->Epoch: 215 | Loss: 0.7779547163126965--->Epoch: 216 | Loss: 0.7767361154183727--->Epoch: 217 | Loss: 0.7755557962756238--->Epoch: 218 | Loss: 0.7744120713397816--->Epoch: 219 | Loss: 0.773303321481535--->Epoch: 220 | Loss: 0.7722279942450311--->Epoch: 221 | Loss: 0.7711846020513687--->Epoch: 222 | Loss: 0.7701717203589462--->Epoch: 223 | Loss: 0.7691879857912974--->Epoch: 224 | Loss: 0.7682320942422305--->Epoch: 225 | Loss: 0.7673027989673162--->Epoch: 226 | Loss: 0.7663989086700111--->Epoch: 227 | Loss: 0.765519285589994--->Epoch: 228 | Loss: 0.7646628436005886--->Epoch: 229 | Loss: 0.763828546321486--->Epoch: 230 | Loss: 0.7630154052523441--->Epoch: 231 | Loss: 0.7622224779322256--->Epoch: 232 | Loss: 0.761448866129269--->Epoch: 233 | Loss: 0.7606937140644222--->Epoch: 234 | Loss: 0.7599562066725649--->Epoch: 235 | Loss: 0.7592355679038474--->Epoch: 236 | Loss: 0.7585310590676191--->Epoch: 237 | Loss: 0.7578419772208981--->Epoch: 238 | Loss: 0.757167653602933--->Epoch: 239 | Loss: 0.7565074521170511--->Epoch: 240 | Loss: 0.7558607678606466--->Epoch: 241 | Loss: 0.7552270257038647--->Epoch: 242 | Loss: 0.7546056789172583--->Epoch: 243 | Loss: 0.7539962078484499--->Epoch: 244 | Loss: 0.7533981186476039--->Epoch: 245 | Loss: 0.7528109420413273--->Epoch: 246 | Loss: 0.7522342321544312--->Epoch: 247 | Loss: 0.7516675653788515--->Epoch: 248 | Loss: 0.7511105392888785--->Epoch: 249 | Loss: 0.7505627716017497--->Epoch: 250 | Loss: 0.750023899182559--->Epoch: 251 | Loss: 0.7494935770923599--->Epoch: 252 | Loss: 0.74897147767828--->Epoch: 253 | Loss: 0.7484572897044119--->Epoch: 254 | Loss: 0.7479507175222144--->Epoch: 255 | Loss: 0.7474514802791284--->Epoch: 256 | Loss: 0.7469593111640941--->Epoch: 257 | Loss: 0.7464739566886559--->Epoch: 258 | Loss: 0.7459951760023353--->Epoch: 259 | Loss: 0.7455227402409604--->Epoch: 260 | Loss: 0.7450564319066563--->Epoch: 261 | Loss: 0.7445960442782139--->Epoch: 262 | Loss: 0.7441413808505813--->Epoch: 263 | Loss: 0.7436922548022408--->Epoch: 264 | Loss: 0.7432484884892719--->Epoch: 265 | Loss: 0.7428099129649218--->Epoch: 266 | Loss: 0.7423763675235447--->Epoch: 267 | Loss: 0.7419476992678019--->Epoch: 268 | Loss: 0.7415237626980499--->Epoch: 269 | Loss: 0.7411044193228828--->Epoch: 270 | Loss: 0.7406895372898252--->Epoch: 271 | Loss: 0.7402789910352159--->Epoch: 272 | Loss: 0.7398726609523549--->Epoch: 273 | Loss: 0.7394704330770213--->Epoch: 274 | Loss: 0.7390721987895104--->Epoch: 275 | Loss: 0.7386778545323681--->Epoch: 276 | Loss: 0.7382873015430402--->Epoch: 277 | Loss: 0.7379004456006842--->Epoch: 278 | Loss: 0.7375171967864276--->Epoch: 279 | Loss: 0.7371374692563851--->Epoch: 280 | Loss: 0.736761181026784--->Epoch: 281 | Loss: 0.736388253770569--->Epoch: 282 | Loss: 0.7360186126248973--->Epoch: 283 | Loss: 0.7356521860089523--->Epoch: 284 | Loss: 0.7352889054515402--->Epoch: 285 | Loss: 0.7349287054279555--->Epoch: 286 | Loss: 0.7345715232056256--->Epoch: 287 | Loss: 0.7342172986980738--->Epoch: 288 | Loss: 0.7338659743267569--->Epoch: 289 | Loss: 0.7335174948903602--->Epoch: 290 | Loss: 0.7331718074411525--->Epoch: 291 | Loss: 0.732828861168024--->Epoch: 292 | Loss: 0.7324886072858473--->Epoch: 293 | Loss: 0.7321509989308242--->Epoch: 294 | Loss: 0.7318159910614961--->Epoch: 295 | Loss: 0.7314835403651105--->Epoch: 296 | Loss: 0.7311536051690569--->Epoch: 297 | Loss: 0.7308261453570979--->Epoch: 298 | Loss: 0.7305011222901331--->Epoch: 299 | Loss: 0.7301784987312538--->Epoch: 300 | Loss: 0.729858238774851--->\n",
            "Epoch: 301 | Loss: 0.7295403077795631--->Epoch: 302 | Loss: 0.7292246723048447--->Epoch: 303 | Loss: 0.7289113000509685--->Epoch: 304 | Loss: 0.7286001598022682--->Epoch: 305 | Loss: 0.7282912213734463--->Epoch: 306 | Loss: 0.7279844555587796--->Epoch: 307 | Loss: 0.7276798340840642--->Epoch: 308 | Loss: 0.7273773295611514--->Epoch: 309 | Loss: 0.7270769154449291--->Epoch: 310 | Loss: 0.7267785659926197--->Epoch: 311 | Loss: 0.7264822562252639--->Epoch: 312 | Loss: 0.7261879618912721--->Epoch: 313 | Loss: 0.7258956594319316--->Epoch: 314 | Loss: 0.7256053259487582--->Epoch: 315 | Loss: 0.725316939172597--->Epoch: 316 | Loss: 0.7250304774343704--->Epoch: 317 | Loss: 0.7247459196373888--->Epoch: 318 | Loss: 0.7244632452311326--->Epoch: 319 | Loss: 0.7241824341864315--->Epoch: 320 | Loss: 0.7239034669719565--->Epoch: 321 | Loss: 0.7236263245319609--->Epoch: 322 | Loss: 0.7233509882651956--->Epoch: 323 | Loss: 0.723077440004937--->Epoch: 324 | Loss: 0.722805662000068--->Epoch: 325 | Loss: 0.7225356368971505--->Epoch: 326 | Loss: 0.7222673477234385--->Epoch: 327 | Loss: 0.7220007778707797--->Epoch: 328 | Loss: 0.7217359110803547--->Epoch: 329 | Loss: 0.721472731428214--->Epoch: 330 | Loss: 0.7212112233115584--->Epoch: 331 | Loss: 0.7209513714357358--->Epoch: 332 | Loss: 0.7206931608019042--->Epoch: 333 | Loss: 0.7204365766953293--->Epoch: 334 | Loss: 0.7201816046742839--->Epoch: 335 | Loss: 0.7199282305595103--->Epoch: 336 | Loss: 0.7196764404242227--->Epoch: 337 | Loss: 0.719426220584613--->Epoch: 338 | Loss: 0.7191775575908386--->Epoch: 339 | Loss: 0.7189304382184607--->Epoch: 340 | Loss: 0.7186848494603146--->Epoch: 341 | Loss: 0.7184407785187829--->Epoch: 342 | Loss: 0.7181982127984528--->Epoch: 343 | Loss: 0.7179571398991367--->Epoch: 344 | Loss: 0.717717547609237--->Epoch: 345 | Loss: 0.7174794238994324--->Epoch: 346 | Loss: 0.717242756916675--->Epoch: 347 | Loss: 0.7170075349784761--->Epoch: 348 | Loss: 0.7167737465674678--->Epoch: 349 | Loss: 0.7165413803262247--->Epoch: 350 | Loss: 0.7163104250523314--->Epoch: 351 | Loss: 0.7160808696936857--->Epoch: 352 | Loss: 0.7158527033440191--->Epoch: 353 | Loss: 0.7156259152386282--->Epoch: 354 | Loss: 0.7154004947503051--->Epoch: 355 | Loss: 0.7151764313854531--->Epoch: 356 | Loss: 0.7149537147803803--->Epoch: 357 | Loss: 0.7147323346977632--->Epoch: 358 | Loss: 0.714512281023267--->Epoch: 359 | Loss: 0.7142935437623182--->Epoch: 360 | Loss: 0.7140761130370201--->Epoch: 361 | Loss: 0.7138599790832034--->Epoch: 362 | Loss: 0.7136451322476044--->Epoch: 363 | Loss: 0.7134315629851677--->Epoch: 364 | Loss: 0.7132192618564606--->Epoch: 365 | Loss: 0.7130082195251989--->Epoch: 366 | Loss: 0.7127984267558773--->Epoch: 367 | Loss: 0.7125898744114953--->Epoch: 368 | Loss: 0.71238255345138--->Epoch: 369 | Loss: 0.7121764549290946--->Epoch: 370 | Loss: 0.7119715699904315--->Epoch: 371 | Loss: 0.7117678898714875--->Epoch: 372 | Loss: 0.711565405896811--->Epoch: 373 | Loss: 0.7113641094776243--->Epoch: 374 | Loss: 0.7111639921101122--->Epoch: 375 | Loss: 0.7109650453737769--->Epoch: 376 | Loss: 0.7107672609298532--->Epoch: 377 | Loss: 0.7105706305197835--->Epoch: 378 | Loss: 0.710375145963748--->Epoch: 379 | Loss: 0.7101807991592474--->Epoch: 380 | Loss: 0.7099875820797361--->Epoch: 381 | Loss: 0.7097954867733052--->Epoch: 382 | Loss: 0.709604505361408--->Epoch: 383 | Loss: 0.7094146300376305--->Epoch: 384 | Loss: 0.7092258530665043--->Epoch: 385 | Loss: 0.7090381667823565--->Epoch: 386 | Loss: 0.7088515635881991--->Epoch: 387 | Loss: 0.7086660359546529--->Epoch: 388 | Loss: 0.7084815764189059--->Epoch: 389 | Loss: 0.7082981775837043--->Epoch: 390 | Loss: 0.7081158321163747--->Epoch: 391 | Loss: 0.707934532747875--->Epoch: 392 | Loss: 0.7077542722718734--->Epoch: 393 | Loss: 0.7075750435438571--->Epoch: 394 | Loss: 0.7073968394802619--->Epoch: 395 | Loss: 0.7072196530576311--->Epoch: 396 | Loss: 0.707043477311795--->Epoch: 397 | Loss: 0.7068683053370731--->Epoch: 398 | Loss: 0.7066941302855005--->Epoch: 399 | Loss: 0.7065209453660708--->Epoch: 400 | Loss: 0.7063487438440009--->\n",
            "Epoch: 401 | Loss: 0.7061775190400157--->Epoch: 402 | Loss: 0.7060072643296487--->Epoch: 403 | Loss: 0.7058379731425604--->Epoch: 404 | Loss: 0.7056696389618751--->Epoch: 405 | Loss: 0.7055022553235308--->Epoch: 406 | Loss: 0.7053358158156472--->Epoch: 407 | Loss: 0.7051703140779059--->Epoch: 408 | Loss: 0.7050057438009465--->Epoch: 409 | Loss: 0.7048420987257754--->Epoch: 410 | Loss: 0.704679372643188--->Epoch: 411 | Loss: 0.7045175593932027--->Epoch: 412 | Loss: 0.7043566528645079--->Epoch: 413 | Loss: 0.7041966469939205--->Epoch: 414 | Loss: 0.7040375357658549--->Epoch: 415 | Loss: 0.7038793132118027--->Epoch: 416 | Loss: 0.7037219734098241--->Epoch: 417 | Loss: 0.7035655104840483--->Epoch: 418 | Loss: 0.7034099186041827--->Epoch: 419 | Loss: 0.703255191985034--->Epoch: 420 | Loss: 0.7031013248860355--->Epoch: 421 | Loss: 0.702948311610785--->Epoch: 422 | Loss: 0.7027961465065895--->Epoch: 423 | Loss: 0.7026448239640211--->Epoch: 424 | Loss: 0.7024943384164756--->Epoch: 425 | Loss: 0.7023446843397453--->Epoch: 426 | Loss: 0.7021958562515923--->Epoch: 427 | Loss: 0.7020478487113346--->Epoch: 428 | Loss: 0.7019006563194359--->Epoch: 429 | Loss: 0.7017542737171032--->Epoch: 430 | Loss: 0.701608695585891--->Epoch: 431 | Loss: 0.7014639166473112--->Epoch: 432 | Loss: 0.7013199316624503--->Epoch: 433 | Loss: 0.7011767354315906--->Epoch: 434 | Loss: 0.70103432279384--->Epoch: 435 | Loss: 0.7008926886267642--->Epoch: 436 | Loss: 0.7007518278460273--->Epoch: 437 | Loss: 0.7006117354050363--->Epoch: 438 | Loss: 0.7004724062945901--->Epoch: 439 | Loss: 0.7003338355425356--->Epoch: 440 | Loss: 0.7001960182134263--->Epoch: 441 | Loss: 0.700058949408189--->Epoch: 442 | Loss: 0.6999226242637908--->Epoch: 443 | Loss: 0.6997870379529144--->Epoch: 444 | Loss: 0.699652185683636--->Epoch: 445 | Loss: 0.6995180626991083--->Epoch: 446 | Loss: 0.6993846642772473--->Epoch: 447 | Loss: 0.6992519857304234--->Epoch: 448 | Loss: 0.6991200224051565--->Epoch: 449 | Loss: 0.6989887696818153--->Epoch: 450 | Loss: 0.6988582229743204--->Epoch: 451 | Loss: 0.6987283777298501--->Epoch: 452 | Loss: 0.6985992294285522--->Epoch: 453 | Loss: 0.6984707735832574--->Epoch: 454 | Loss: 0.6983430057391966--->Epoch: 455 | Loss: 0.6982159214737231--->Epoch: 456 | Loss: 0.6980895163960359--->Epoch: 457 | Loss: 0.6979637861469077--->Epoch: 458 | Loss: 0.6978387263984172--->Epoch: 459 | Loss: 0.6977143328536819--->Epoch: 460 | Loss: 0.6975906012465959--->Epoch: 461 | Loss: 0.697467527341571--->Epoch: 462 | Loss: 0.6973451069332796--->Epoch: 463 | Loss: 0.6972233358464015--->Epoch: 464 | Loss: 0.697102209935373--->Epoch: 465 | Loss: 0.6969817250841388--->Epoch: 466 | Loss: 0.6968618772059083--->Epoch: 467 | Loss: 0.696742662242912--->Epoch: 468 | Loss: 0.6966240761661621--->Epoch: 469 | Loss: 0.6965061149752163--->Epoch: 470 | Loss: 0.6963887746979434--->Epoch: 471 | Loss: 0.69627205139029--->Epoch: 472 | Loss: 0.6961559411360544--->Epoch: 473 | Loss: 0.6960404400466569--->Epoch: 474 | Loss: 0.6959255442609162--->Epoch: 475 | Loss: 0.6958112499448288--->Epoch: 476 | Loss: 0.6956975532913476--->Epoch: 477 | Loss: 0.695584450520166--->Epoch: 478 | Loss: 0.6954719378775024--->Epoch: 479 | Loss: 0.6953600116358869--->Epoch: 480 | Loss: 0.6952486680939516--->Epoch: 481 | Loss: 0.6951379035762222--->Epoch: 482 | Loss: 0.6950277144329103--->Epoch: 483 | Loss: 0.6949180970397119--->Epoch: 484 | Loss: 0.6948090477976024--->Epoch: 485 | Loss: 0.694700563132639--->Epoch: 486 | Loss: 0.6945926394957609--->Epoch: 487 | Loss: 0.6944852733625945--->Epoch: 488 | Loss: 0.6943784612332584--->Epoch: 489 | Loss: 0.6942721996321722--->Epoch: 490 | Loss: 0.6941664851078648--->Epoch: 491 | Loss: 0.6940613142327874--->Epoch: 492 | Loss: 0.6939566836031265--->Epoch: 493 | Loss: 0.6938525898386182--->Epoch: 494 | Loss: 0.693749029582367--->Epoch: 495 | Loss: 0.6936459995006629--->Epoch: 496 | Loss: 0.6935434962828031--->Epoch: 497 | Loss: 0.6934415166409134--->Epoch: 498 | Loss: 0.6933400573097726--->Epoch: 499 | Loss: 0.6932391150466386--->Epoch: 500 | Loss: 0.6931386866310743--->\n",
            "Epoch: 501 | Loss: 0.6930387688647781--->Epoch: 502 | Loss: 0.6929393585714126--->Epoch: 503 | Loss: 0.6928404525964387--->Epoch: 504 | Loss: 0.6927420478069476--->Epoch: 505 | Loss: 0.6926441410914963--->Epoch: 506 | Loss: 0.6925467293599451--->Epoch: 507 | Loss: 0.692449809543295--->Epoch: 508 | Loss: 0.6923533785935276--->Epoch: 509 | Loss: 0.6922574334834461--->Epoch: 510 | Loss: 0.6921619712065183--->Epoch: 511 | Loss: 0.6920669887767203--->Epoch: 512 | Loss: 0.6919724832283818--->Epoch: 513 | Loss: 0.691878451616033--->Epoch: 514 | Loss: 0.6917848910142533--->Epoch: 515 | Loss: 0.6916917985175202--->Epoch: 516 | Loss: 0.6915991712400602--->Epoch: 517 | Loss: 0.6915070063157016--->Epoch: 518 | Loss: 0.6914153008977273--->Epoch: 519 | Loss: 0.6913240521587299--->Epoch: 520 | Loss: 0.6912332572904688--->Epoch: 521 | Loss: 0.691142913503725--->Epoch: 522 | Loss: 0.6910530180281631--->Epoch: 523 | Loss: 0.6909635681121878--->Epoch: 524 | Loss: 0.6908745610228076--->Epoch: 525 | Loss: 0.6907859940454957--->Epoch: 526 | Loss: 0.690697864484053--->Epoch: 527 | Loss: 0.6906101696604751--->Epoch: 528 | Loss: 0.6905229069148144--->Epoch: 529 | Loss: 0.6904360736050512--->Epoch: 530 | Loss: 0.6903496671069582--->Epoch: 531 | Loss: 0.6902636848139718--->Epoch: 532 | Loss: 0.6901781241370621--->Epoch: 533 | Loss: 0.6900929825046033--->Epoch: 534 | Loss: 0.6900082573622478--->Epoch: 535 | Loss: 0.6899239461727983--->Epoch: 536 | Loss: 0.6898400464160837--->Epoch: 537 | Loss: 0.6897565555888334--->Epoch: 538 | Loss: 0.689673471204556--->Epoch: 539 | Loss: 0.6895907907934147--->Epoch: 540 | Loss: 0.6895085119021083--->Epoch: 541 | Loss: 0.6894266320937492--->Epoch: 542 | Loss: 0.6893451489477458--->Epoch: 543 | Loss: 0.6892640600596829--->Epoch: 544 | Loss: 0.689183363041205--->Epoch: 545 | Loss: 0.6891030555199009--->Epoch: 546 | Loss: 0.6890231351391862--->Epoch: 547 | Loss: 0.6889435995581918--->Epoch: 548 | Loss: 0.6888644464516475--->Epoch: 549 | Loss: 0.6887856735097717--->Epoch: 550 | Loss: 0.6887072784381588--->Epoch: 551 | Loss: 0.6886292589576688--->Epoch: 552 | Loss: 0.6885516128043173--->Epoch: 553 | Loss: 0.6884743377291667--->Epoch: 554 | Loss: 0.6883974314982182--->Epoch: 555 | Loss: 0.6883208918923045--->Epoch: 556 | Loss: 0.6882447167069837--->Epoch: 557 | Loss: 0.688168903752434--->Epoch: 558 | Loss: 0.6880934508533484--->Epoch: 559 | Loss: 0.6880183558488315--->Epoch: 560 | Loss: 0.6879436165922971--->Epoch: 561 | Loss: 0.6878692309513642--->Epoch: 562 | Loss: 0.6877951968077581--->Epoch: 563 | Loss: 0.6877215120572081--->Epoch: 564 | Loss: 0.6876481746093486--->Epoch: 565 | Loss: 0.6875751823876197--->Epoch: 566 | Loss: 0.68750253332917--->Epoch: 567 | Loss: 0.687430225384758--->Epoch: 568 | Loss: 0.6873582565186566--->Epoch: 569 | Loss: 0.6872866247085556--->Epoch: 570 | Loss: 0.6872153279454694--->Epoch: 571 | Loss: 0.6871443642336398--->Epoch: 572 | Loss: 0.6870737315904439--->Epoch: 573 | Loss: 0.687003428046301--->Epoch: 574 | Loss: 0.6869334516445802--->Epoch: 575 | Loss: 0.6868638004415091--->Epoch: 576 | Loss: 0.6867944725060832--->Epoch: 577 | Loss: 0.6867254659199752--->Epoch: 578 | Loss: 0.6866567787774471--->Epoch: 579 | Loss: 0.6865884091852599--->Epoch: 580 | Loss: 0.6865203552625861--->Epoch: 581 | Loss: 0.6864526151409237--->Epoch: 582 | Loss: 0.6863851869640075--->Epoch: 583 | Loss: 0.686318068887725--->Epoch: 584 | Loss: 0.6862512590800295--->Epoch: 585 | Loss: 0.6861847557208569--->Epoch: 586 | Loss: 0.6861185570020408--->Epoch: 587 | Loss: 0.6860526611272296--->Epoch: 588 | Loss: 0.6859870663118033--->Epoch: 589 | Loss: 0.6859217707827916--->Epoch: 590 | Loss: 0.685856772778793--->Epoch: 591 | Loss: 0.6857920705498931--->Epoch: 592 | Loss: 0.6857276623575849--->Epoch: 593 | Loss: 0.6856635464746887--->Epoch: 594 | Loss: 0.6855997211852742--->Epoch: 595 | Loss: 0.6855361847845802--->Epoch: 596 | Loss: 0.6854729355789384--->Epoch: 597 | Loss: 0.6854099718856952--->Epoch: 598 | Loss: 0.6853472920331362--->Epoch: 599 | Loss: 0.6852848943604085--->Epoch: 600 | Loss: 0.685222777217446--->\n",
            "Epoch: 601 | Loss: 0.6851609389648948--->Epoch: 602 | Loss: 0.6850993779740383--->Epoch: 603 | Loss: 0.6850380926267231--->Epoch: 604 | Loss: 0.6849770813152866--->Epoch: 605 | Loss: 0.6849163424424835--->Epoch: 606 | Loss: 0.6848558744214137--->Epoch: 607 | Loss: 0.6847956756754513--->Epoch: 608 | Loss: 0.6847357446381721--->Epoch: 609 | Loss: 0.6846760797532847--->Epoch: 610 | Loss: 0.6846166794745591--->Epoch: 611 | Loss: 0.6845575422657576--->Epoch: 612 | Loss: 0.6844986666005664--->Epoch: 613 | Loss: 0.684440050962525--->Epoch: 614 | Loss: 0.6843816938449614--->Epoch: 615 | Loss: 0.6843235937509219--->Epoch: 616 | Loss: 0.6842657491931047--->Epoch: 617 | Loss: 0.6842081586937941--->Epoch: 618 | Loss: 0.6841508207847941--->Epoch: 619 | Loss: 0.6840937340073625--->Epoch: 620 | Loss: 0.6840368969121459--->Epoch: 621 | Loss: 0.683980308059116--->Epoch: 622 | Loss: 0.6839239660175042--->Epoch: 623 | Loss: 0.6838678693657386--->Epoch: 624 | Loss: 0.6838120166913807--->Epoch: 625 | Loss: 0.6837564065910631--->Epoch: 626 | Loss: 0.6837010376704264--->Epoch: 627 | Loss: 0.6836459085440585--->Epoch: 628 | Loss: 0.6835910178354321--->Epoch: 629 | Loss: 0.6835363641768442--->Epoch: 630 | Loss: 0.6834819462093559--->Epoch: 631 | Loss: 0.6834277625827327--->Epoch: 632 | Loss: 0.6833738119553838--->Epoch: 633 | Loss: 0.6833200929943042--->Epoch: 634 | Loss: 0.6832666043750146--->Epoch: 635 | Loss: 0.6832133447815045--->Epoch: 636 | Loss: 0.6831603129061737--->Epoch: 637 | Loss: 0.6831075074497743--->Epoch: 638 | Loss: 0.6830549271213552--->Epoch: 639 | Loss: 0.6830025706382032--->Epoch: 640 | Loss: 0.6829504367257894--->Epoch: 641 | Loss: 0.6828985241177113--->Epoch: 642 | Loss: 0.6828468315556389--->Epoch: 643 | Loss: 0.6827953577892577--->Epoch: 644 | Loss: 0.6827441015762167--->Epoch: 645 | Loss: 0.6826930616820726--->Epoch: 646 | Loss: 0.6826422368802354--->Epoch: 647 | Loss: 0.6825916259519171--->Epoch: 648 | Loss: 0.6825412276860765--->Epoch: 649 | Loss: 0.682491040879368--->Epoch: 650 | Loss: 0.6824410643360881--->Epoch: 651 | Loss: 0.6823912968681248--->Epoch: 652 | Loss: 0.6823417372949049--->Epoch: 653 | Loss: 0.6822923844433436--->Epoch: 654 | Loss: 0.6822432371477932--->Epoch: 655 | Loss: 0.6821942942499934--->Epoch: 656 | Loss: 0.6821455545990203--->Epoch: 657 | Loss: 0.6820970170512369--->Epoch: 658 | Loss: 0.6820486804702447--->Epoch: 659 | Loss: 0.682000543726833--->Epoch: 660 | Loss: 0.6819526056989323--->Epoch: 661 | Loss: 0.6819048652715641--->Epoch: 662 | Loss: 0.6818573213367938--->Epoch: 663 | Loss: 0.6818099727936833--->Epoch: 664 | Loss: 0.681762818548243--->Epoch: 665 | Loss: 0.6817158575133861--->Epoch: 666 | Loss: 0.6816690886088805--->Epoch: 667 | Loss: 0.6816225107613031--->Epoch: 668 | Loss: 0.6815761229039946--->Epoch: 669 | Loss: 0.6815299239770128--->Epoch: 670 | Loss: 0.6814839129270881--->Epoch: 671 | Loss: 0.6814380887075776--->Epoch: 672 | Loss: 0.6813924502784214--->Epoch: 673 | Loss: 0.6813469966060982--->Epoch: 674 | Loss: 0.6813017266635806--->Epoch: 675 | Loss: 0.6812566394302919--->Epoch: 676 | Loss: 0.6812117338920625--->Epoch: 677 | Loss: 0.6811670090410873--->Epoch: 678 | Loss: 0.6811224638758815--->Epoch: 679 | Loss: 0.6810780974012403--->Epoch: 680 | Loss: 0.6810339086281951--->Epoch: 681 | Loss: 0.680989896573972--->Epoch: 682 | Loss: 0.6809460602619503--->Epoch: 683 | Loss: 0.6809023987216213--->Epoch: 684 | Loss: 0.6808589109885469--->Epoch: 685 | Loss: 0.6808155961043201--->Epoch: 686 | Loss: 0.6807724531165225--->Epoch: 687 | Loss: 0.6807294810786862--->Epoch: 688 | Loss: 0.6806866790502528--->Epoch: 689 | Loss: 0.6806440460965341--->Epoch: 690 | Loss: 0.680601581288673--->Epoch: 691 | Loss: 0.680559283703604--->Epoch: 692 | Loss: 0.6805171524240151--->Epoch: 693 | Loss: 0.6804751865383092--->Epoch: 694 | Loss: 0.6804333851405651--->Epoch: 695 | Loss: 0.6803917473305011--->Epoch: 696 | Loss: 0.6803502722134352--->Epoch: 697 | Loss: 0.6803089589002506--->Epoch: 698 | Loss: 0.6802678065073554--->Epoch: 699 | Loss: 0.680226814156648--->Epoch: 700 | Loss: 0.6801859809754798--->\n",
            "Epoch: 701 | Loss: 0.6801453060966188--->Epoch: 702 | Loss: 0.6801047886582129--->Epoch: 703 | Loss: 0.6800644278037555--->Epoch: 704 | Loss: 0.6800242226820487--->Epoch: 705 | Loss: 0.6799841724471678--->Epoch: 706 | Loss: 0.6799442762584278--->Epoch: 707 | Loss: 0.6799045332803467--->Epoch: 708 | Loss: 0.679864942682612--->Epoch: 709 | Loss: 0.679825503640046--->Epoch: 710 | Loss: 0.6797862153325712--->Epoch: 711 | Loss: 0.6797470769451778--->Epoch: 712 | Loss: 0.6797080876678884--->Epoch: 713 | Loss: 0.6796692466957259--->Epoch: 714 | Loss: 0.6796305532286793--->Epoch: 715 | Loss: 0.6795920064716717--->Epoch: 716 | Loss: 0.679553605634527--->Epoch: 717 | Loss: 0.6795153499319371--->Epoch: 718 | Loss: 0.6794772385834309--->Epoch: 719 | Loss: 0.6794392708133405--->Epoch: 720 | Loss: 0.6794014458507714--->Epoch: 721 | Loss: 0.6793637629295689--->Epoch: 722 | Loss: 0.6793262212882883--->Epoch: 723 | Loss: 0.6792888201701628--->Epoch: 724 | Loss: 0.6792515588230731--->Epoch: 725 | Loss: 0.6792144364995165--->Epoch: 726 | Loss: 0.6791774524565762--->Epoch: 727 | Loss: 0.6791406059558915--->Epoch: 728 | Loss: 0.6791038962636272--->Epoch: 729 | Loss: 0.679067322650444--->Epoch: 730 | Loss: 0.6790308843914689--->Epoch: 731 | Loss: 0.6789945807662654--->Epoch: 732 | Loss: 0.678958411058805--->Epoch: 733 | Loss: 0.678922374557437--->Epoch: 734 | Loss: 0.6788864705548605--->Epoch: 735 | Loss: 0.6788506983480962--->Epoch: 736 | Loss: 0.6788150572384563--->Epoch: 737 | Loss: 0.6787795465315181--->Epoch: 738 | Loss: 0.6787441655370944--->Epoch: 739 | Loss: 0.678708913569207--->Epoch: 740 | Loss: 0.6786737899460584--->Epoch: 741 | Loss: 0.6786387939900034--->Epoch: 742 | Loss: 0.6786039250275234--->Epoch: 743 | Loss: 0.6785691823891996--->Epoch: 744 | Loss: 0.6785345654096832--->Epoch: 745 | Loss: 0.6785000734276718--->Epoch: 746 | Loss: 0.6784657057858818--->Epoch: 747 | Loss: 0.6784314618310215--->Epoch: 748 | Loss: 0.6783973409137656--->Epoch: 749 | Loss: 0.6783633423887286--->Epoch: 750 | Loss: 0.6783294656144402--->Epoch: 751 | Loss: 0.6782957099533179--->Epoch: 752 | Loss: 0.6782620747716431--->Epoch: 753 | Loss: 0.6782285594395353--->Epoch: 754 | Loss: 0.6781951633309263--->Epoch: 755 | Loss: 0.6781618858235369--->Epoch: 756 | Loss: 0.67812872629885--->Epoch: 757 | Loss: 0.6780956841420881--->Epoch: 758 | Loss: 0.6780627587421874--->Epoch: 759 | Loss: 0.6780299494917742--->Epoch: 760 | Loss: 0.6779972557871411--->Epoch: 761 | Loss: 0.677964677028222--->Epoch: 762 | Loss: 0.6779322126185702--->Epoch: 763 | Loss: 0.677899861965332--->Epoch: 764 | Loss: 0.6778676244792265--->Epoch: 765 | Loss: 0.6778354995745203--->Epoch: 766 | Loss: 0.6778034866690045--->Epoch: 767 | Loss: 0.6777715851839725--->Epoch: 768 | Loss: 0.6777397945441966--->Epoch: 769 | Loss: 0.6777081141779063--->Epoch: 770 | Loss: 0.6776765435167644--->Epoch: 771 | Loss: 0.6776450819958462--->Epoch: 772 | Loss: 0.6776137290536156--->Epoch: 773 | Loss: 0.6775824841319048--->Epoch: 774 | Loss: 0.6775513466758916--->Epoch: 775 | Loss: 0.6775203161340778--->Epoch: 776 | Loss: 0.6774893919582675--->Epoch: 777 | Loss: 0.6774585736035461--->Epoch: 778 | Loss: 0.6774278605282583--->Epoch: 779 | Loss: 0.6773972521939878--->Epoch: 780 | Loss: 0.6773667480655362--->Epoch: 781 | Loss: 0.6773363476109011--->Epoch: 782 | Loss: 0.6773060503012569--->Epoch: 783 | Loss: 0.6772758556109336--->Epoch: 784 | Loss: 0.6772457630173963--->Epoch: 785 | Loss: 0.6772157720012247--->Epoch: 786 | Loss: 0.6771858820460935--->Epoch: 787 | Loss: 0.6771560926387524--->Epoch: 788 | Loss: 0.677126403269006--->Epoch: 789 | Loss: 0.6770968134296935--->Epoch: 790 | Loss: 0.6770673226166707--->Epoch: 791 | Loss: 0.6770379303287891--->Epoch: 792 | Loss: 0.6770086360678768--->Epoch: 793 | Loss: 0.6769794393387198--->Epoch: 794 | Loss: 0.6769503396490432--->Epoch: 795 | Loss: 0.6769213365094913--->Epoch: 796 | Loss: 0.6768924294336093--->Epoch: 797 | Loss: 0.6768636179378246--->Epoch: 798 | Loss: 0.676834901541429--->Epoch: 799 | Loss: 0.6768062797665585--->Epoch: 800 | Loss: 0.6767777521381768--->\n",
            "Epoch: 801 | Loss: 0.6767493181840565--->Epoch: 802 | Loss: 0.6767209774347602--->Epoch: 803 | Loss: 0.6766927294236247--->Epoch: 804 | Loss: 0.6766645736867406--->Epoch: 805 | Loss: 0.6766365097629367--->Epoch: 806 | Loss: 0.6766085371937612--->Epoch: 807 | Loss: 0.676580655523465--->Epoch: 808 | Loss: 0.6765528642989843--->Epoch: 809 | Loss: 0.6765251630699225--->Epoch: 810 | Loss: 0.6764975513885342--->Epoch: 811 | Loss: 0.6764700288097081--->Epoch: 812 | Loss: 0.6764425948909497--->Epoch: 813 | Loss: 0.6764152491923647--->Epoch: 814 | Loss: 0.6763879912766426--->Epoch: 815 | Loss: 0.6763608207090397--->Epoch: 816 | Loss: 0.6763337370573637--->Epoch: 817 | Loss: 0.6763067398919558--->Epoch: 818 | Loss: 0.6762798287856763--->Epoch: 819 | Loss: 0.6762530033138874--->Epoch: 820 | Loss: 0.6762262630544377--->Epoch: 821 | Loss: 0.6761996075876456--->Epoch: 822 | Loss: 0.6761730364962849--->Epoch: 823 | Loss: 0.6761465493655683--->Epoch: 824 | Loss: 0.6761201457831313--->Epoch: 825 | Loss: 0.6760938253390184--->Epoch: 826 | Loss: 0.6760675876256663--->Epoch: 827 | Loss: 0.6760414322378893--->Epoch: 828 | Loss: 0.6760153587728639--->Epoch: 829 | Loss: 0.6759893668301146--->Epoch: 830 | Loss: 0.6759634560114978--->Epoch: 831 | Loss: 0.6759376259211878--->Epoch: 832 | Loss: 0.6759118761656617--->Epoch: 833 | Loss: 0.6758862063536852--->Epoch: 834 | Loss: 0.6758606160962978--->Epoch: 835 | Loss: 0.6758351050067982--->Epoch: 836 | Loss: 0.6758096727007303--->Epoch: 837 | Loss: 0.6757843187958691--->Epoch: 838 | Loss: 0.6757590429122056--->Epoch: 839 | Loss: 0.6757338446719348--->Epoch: 840 | Loss: 0.675708723699439--->Epoch: 841 | Loss: 0.6756836796212766--->Epoch: 842 | Loss: 0.675658712066167--->Epoch: 843 | Loss: 0.6756338206649762--->Epoch: 844 | Loss: 0.6756090050507054--->Epoch: 845 | Loss: 0.6755842648584754--->Epoch: 846 | Loss: 0.6755595997255146--->Epoch: 847 | Loss: 0.6755350092911451--->Epoch: 848 | Loss: 0.6755104931967696--->Epoch: 849 | Loss: 0.6754860510858578--->Epoch: 850 | Loss: 0.6754616826039348--->Epoch: 851 | Loss: 0.6754373873985664--->Epoch: 852 | Loss: 0.6754131651193477--->Epoch: 853 | Loss: 0.6753890154178888--->Epoch: 854 | Loss: 0.6753649379478041--->Epoch: 855 | Loss: 0.6753409323646979--->Epoch: 856 | Loss: 0.6753169983261526--->Epoch: 857 | Loss: 0.6752931354917168--->Epoch: 858 | Loss: 0.6752693435228916--->Epoch: 859 | Loss: 0.67524562208312--->Epoch: 860 | Loss: 0.6752219708377735--->Epoch: 861 | Loss: 0.6751983894541401--->Epoch: 862 | Loss: 0.675174877601413--->Epoch: 863 | Loss: 0.675151434950678--->Epoch: 864 | Loss: 0.675128061174902--->Epoch: 865 | Loss: 0.6751047559489205--->Epoch: 866 | Loss: 0.6750815189494276--->Epoch: 867 | Loss: 0.6750583498549618--->Epoch: 868 | Loss: 0.6750352483458972--->Epoch: 869 | Loss: 0.6750122141044305--->Epoch: 870 | Loss: 0.6749892468145686--->Epoch: 871 | Loss: 0.67496634616212--->Epoch: 872 | Loss: 0.6749435118346813--->Epoch: 873 | Loss: 0.6749207435216273--->Epoch: 874 | Loss: 0.6748980409140989--->Epoch: 875 | Loss: 0.6748754037049929--->Epoch: 876 | Loss: 0.6748528315889506--->Epoch: 877 | Loss: 0.6748303242623472--->Epoch: 878 | Loss: 0.6748078814232806--->Epoch: 879 | Loss: 0.6747855027715615--->Epoch: 880 | Loss: 0.6747631880087015--->Epoch: 881 | Loss: 0.6747409368379037--->Epoch: 882 | Loss: 0.6747187489640515--->Epoch: 883 | Loss: 0.6746966240936983--->Epoch: 884 | Loss: 0.6746745619350573--->Epoch: 885 | Loss: 0.6746525621979906--->Epoch: 886 | Loss: 0.6746306245940002--->Epoch: 887 | Loss: 0.6746087488362162--->Epoch: 888 | Loss: 0.674586934639388--->Epoch: 889 | Loss: 0.6745651817198738--->Epoch: 890 | Loss: 0.6745434897956303--->Epoch: 891 | Loss: 0.6745218585862033--->Epoch: 892 | Loss: 0.6745002878127175--->Epoch: 893 | Loss: 0.6744787771978675--->Epoch: 894 | Loss: 0.6744573264659067--->Epoch: 895 | Loss: 0.6744359353426385--->Epoch: 896 | Loss: 0.6744146035554069--->Epoch: 897 | Loss: 0.6743933308330873--->Epoch: 898 | Loss: 0.6743721169060753--->Epoch: 899 | Loss: 0.6743509615062794--->Epoch: 900 | Loss: 0.67432986436711--->\n",
            "Epoch: 901 | Loss: 0.6743088252234714--->Epoch: 902 | Loss: 0.6742878438117517--->Epoch: 903 | Loss: 0.6742669198698146--->Epoch: 904 | Loss: 0.6742460531369886--->Epoch: 905 | Loss: 0.6742252433540606--->Epoch: 906 | Loss: 0.674204490263264--->Epoch: 907 | Loss: 0.6741837936082722--->Epoch: 908 | Loss: 0.674163153134188--->Epoch: 909 | Loss: 0.674142568587536--->Epoch: 910 | Loss: 0.6741220397162534--->Epoch: 911 | Loss: 0.6741015662696812--->Epoch: 912 | Loss: 0.6740811479985556--->Epoch: 913 | Loss: 0.6740607846549997--->Epoch: 914 | Loss: 0.6740404759925152--->Epoch: 915 | Loss: 0.6740202217659729--->Epoch: 916 | Loss: 0.6740000217316052--->Epoch: 917 | Loss: 0.6739798756469979--->Epoch: 918 | Loss: 0.6739597832710811--->Epoch: 919 | Loss: 0.6739397443641219--->Epoch: 920 | Loss: 0.673919758687715--->Epoch: 921 | Loss: 0.6738998260047762--->Epoch: 922 | Loss: 0.6738799460795325--->Epoch: 923 | Loss: 0.6738601186775157--->Epoch: 924 | Loss: 0.6738403435655536--->Epoch: 925 | Loss: 0.6738206205117622--->Epoch: 926 | Loss: 0.6738009492855377--->Epoch: 927 | Loss: 0.6737813296575488--->Epoch: 928 | Loss: 0.6737617613997294--->Epoch: 929 | Loss: 0.6737422442852702--->Epoch: 930 | Loss: 0.6737227780886113--->Epoch: 931 | Loss: 0.6737033625854343--->Epoch: 932 | Loss: 0.6736839975526558--->Epoch: 933 | Loss: 0.6736646827684184--->Epoch: 934 | Loss: 0.6736454180120844--->Epoch: 935 | Loss: 0.6736262030642276--->Epoch: 936 | Loss: 0.6736070377066267--->Epoch: 937 | Loss: 0.6735879217222569--->Epoch: 938 | Loss: 0.6735688548952841--->Epoch: 939 | Loss: 0.6735498370110561--->Epoch: 940 | Loss: 0.6735308678560966--->Epoch: 941 | Loss: 0.6735119472180978--->Epoch: 942 | Loss: 0.6734930748859126--->Epoch: 943 | Loss: 0.6734742506495489--->Epoch: 944 | Loss: 0.673455474300161--->Epoch: 945 | Loss: 0.6734367456300439--->Epoch: 946 | Loss: 0.6734180644326263--->Epoch: 947 | Loss: 0.6733994305024625--->Epoch: 948 | Loss: 0.6733808436352279--->Epoch: 949 | Loss: 0.6733623036277093--->Epoch: 950 | Loss: 0.673343810277801--->Epoch: 951 | Loss: 0.673325363384496--->Epoch: 952 | Loss: 0.6733069627478804--->Epoch: 953 | Loss: 0.6732886081691267--->Epoch: 954 | Loss: 0.6732702994504877--->Epoch: 955 | Loss: 0.6732520363952881--->Epoch: 956 | Loss: 0.6732338188079207--->Epoch: 957 | Loss: 0.6732156464938376--->Epoch: 958 | Loss: 0.6731975192595459--->Epoch: 959 | Loss: 0.6731794369125993--->Epoch: 960 | Loss: 0.6731613992615932--->Epoch: 961 | Loss: 0.6731434061161586--->Epoch: 962 | Loss: 0.6731254572869544--->Epoch: 963 | Loss: 0.6731075525856626--->Epoch: 964 | Loss: 0.6730896918249819--->Epoch: 965 | Loss: 0.673071874818621--->Epoch: 966 | Loss: 0.6730541013812928--->Epoch: 967 | Loss: 0.6730363713287092--->Epoch: 968 | Loss: 0.6730186844775737--->Epoch: 969 | Loss: 0.673001040645577--->Epoch: 970 | Loss: 0.672983439651389--->Epoch: 971 | Loss: 0.6729658813146554--->Epoch: 972 | Loss: 0.6729483654559902--->Epoch: 973 | Loss: 0.6729308918969702--->Epoch: 974 | Loss: 0.6729134604601296--->Epoch: 975 | Loss: 0.6728960709689541--->Epoch: 976 | Loss: 0.672878723247875--->Epoch: 977 | Loss: 0.672861417122264--->Epoch: 978 | Loss: 0.6728441524184272--->Epoch: 979 | Loss: 0.6728269289635995--->Epoch: 980 | Loss: 0.6728097465859395--->Epoch: 981 | Loss: 0.672792605114524--->Epoch: 982 | Loss: 0.6727755043793411--->Epoch: 983 | Loss: 0.6727584442112872--->Epoch: 984 | Loss: 0.6727414244421595--->Epoch: 985 | Loss: 0.6727244449046516--->Epoch: 986 | Loss: 0.6727075054323484--->Epoch: 987 | Loss: 0.6726906058597198--->Epoch: 988 | Loss: 0.6726737460221167--->Epoch: 989 | Loss: 0.6726569257557644--->Epoch: 990 | Loss: 0.6726401448977588--->Epoch: 991 | Loss: 0.67262340328606--->Epoch: 992 | Loss: 0.672606700759488--->Epoch: 993 | Loss: 0.6725900371577171--->Epoch: 994 | Loss: 0.6725734123212714--->Epoch: 995 | Loss: 0.6725568260915193--->Epoch: 996 | Loss: 0.6725402783106686--->Epoch: 997 | Loss: 0.6725237688217613--->Epoch: 998 | Loss: 0.6725072974686696--->Epoch: 999 | Loss: 0.672490864096089--->Epoch: 1000 | Loss: 0.6724744685495365--->\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[ 0.1241],\n",
              "         [ 0.1082],\n",
              "         [ 0.2474],\n",
              "         [-0.0614],\n",
              "         [ 0.1777],\n",
              "         [-0.2915],\n",
              "         [-0.3862],\n",
              "         [-0.5279],\n",
              "         [-0.2014],\n",
              "         [ 0.4445],\n",
              "         [ 0.3143],\n",
              "         [ 0.3223],\n",
              "         [-0.1690],\n",
              "         [-0.1413],\n",
              "         [-0.0282],\n",
              "         [-0.2103],\n",
              "         [-0.0805],\n",
              "         [ 0.3688],\n",
              "         [-0.1018],\n",
              "         [-0.0557],\n",
              "         [ 0.1389],\n",
              "         [-0.2980],\n",
              "         [ 0.2884],\n",
              "         [-0.1072],\n",
              "         [-0.0548],\n",
              "         [ 0.1375],\n",
              "         [ 0.4182],\n",
              "         [ 0.0565],\n",
              "         [ 0.2322],\n",
              "         [-0.1746]], dtype=torch.float64, requires_grad=True),\n",
              " tensor([-0.5069], dtype=torch.float64, requires_grad=True))"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  y_pred = model.forward(X_test_tensor)\n",
        "  y_pred = (y_pred > 0.5).float()\n",
        "  accuracy = (y_pred == Y_test_tensor).float().mean()\n",
        "  print(f'Accuracy: {accuracy.item()}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S9sbBnW-DVVm",
        "outputId": "9684df63-f75e-499d-ee83-6555f3a28be0"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.5812557935714722\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lhUUpLbRDVEr"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1Cj8IU7wDVBP"
      },
      "execution_count": 77,
      "outputs": []
    }
  ]
}